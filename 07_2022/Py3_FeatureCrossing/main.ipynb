{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n14573    -122.16     37.76                36.0       2781.0           574.0   \n11607    -121.28     37.94                44.0       1406.0           357.0   \n1644     -117.24     34.59                 4.0       5027.0           797.0   \n2886     -117.75     34.07                52.0       1548.0           348.0   \n11833    -121.34     38.69                16.0       2686.0           516.0   \n\n       population  households  median_income  median_house_value  \n14573      1438.0       519.0         2.4598               155.5  \n11607      1489.0       386.0         1.4688                56.8  \n1644       1869.0       686.0         3.5507               186.1  \n2886       1131.0       343.0         2.6300               127.3  \n11833      1553.0       529.0         3.7857               112.7  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>housing_median_age</th>\n      <th>total_rooms</th>\n      <th>total_bedrooms</th>\n      <th>population</th>\n      <th>households</th>\n      <th>median_income</th>\n      <th>median_house_value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14573</th>\n      <td>-122.16</td>\n      <td>37.76</td>\n      <td>36.0</td>\n      <td>2781.0</td>\n      <td>574.0</td>\n      <td>1438.0</td>\n      <td>519.0</td>\n      <td>2.4598</td>\n      <td>155.5</td>\n    </tr>\n    <tr>\n      <th>11607</th>\n      <td>-121.28</td>\n      <td>37.94</td>\n      <td>44.0</td>\n      <td>1406.0</td>\n      <td>357.0</td>\n      <td>1489.0</td>\n      <td>386.0</td>\n      <td>1.4688</td>\n      <td>56.8</td>\n    </tr>\n    <tr>\n      <th>1644</th>\n      <td>-117.24</td>\n      <td>34.59</td>\n      <td>4.0</td>\n      <td>5027.0</td>\n      <td>797.0</td>\n      <td>1869.0</td>\n      <td>686.0</td>\n      <td>3.5507</td>\n      <td>186.1</td>\n    </tr>\n    <tr>\n      <th>2886</th>\n      <td>-117.75</td>\n      <td>34.07</td>\n      <td>52.0</td>\n      <td>1548.0</td>\n      <td>348.0</td>\n      <td>1131.0</td>\n      <td>343.0</td>\n      <td>2.6300</td>\n      <td>127.3</td>\n    </tr>\n    <tr>\n      <th>11833</th>\n      <td>-121.34</td>\n      <td>38.69</td>\n      <td>16.0</td>\n      <td>2686.0</td>\n      <td>516.0</td>\n      <td>1553.0</td>\n      <td>529.0</td>\n      <td>3.7857</td>\n      <td>112.7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\")\n",
    "test_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv\")\n",
    "\n",
    "# Scale the labels\n",
    "scale_factor = 1000.0\n",
    "# Scale the training set's label.\n",
    "train_df[\"median_house_value\"] /= scale_factor\n",
    "train_df = train_df.reindex(np.random.permutation(train_df.index))\n",
    "\n",
    "# Scale the test set's label\n",
    "test_df[\"median_house_value\"] /= scale_factor\n",
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "feature_cols = []\n",
    "resolution_in_degrees = 0.4\n",
    "\n",
    "# merepresentasikan kolom-kolom yang akan digunakan sebagai feature\n",
    "lat_col = tf.feature_column.numeric_column(\"latitude\")\n",
    "\n",
    "# bikin np.array dari latitude terkecil sampai terbesar dengan resolusi / interval 1\n",
    "lat_boundaries = list(np.arange(int(min(train_df[\"latitude\"])), int(max(train_df[\"latitude\"])), resolution_in_degrees))\n",
    "\n",
    "# bikin tempat untuk mewadahi latitude dengan bucket / binning sekian\n",
    "latitude = tf.feature_column.bucketized_column(lat_col, boundaries=lat_boundaries)\n",
    "\n",
    "long_col = tf.feature_column.numeric_column(\"longitude\")\n",
    "long_boundaries = list(np.arange(int(min(train_df[\"longitude\"])), int(max(train_df[\"longitude\"])), resolution_in_degrees))\n",
    "longitude = tf.feature_column.bucketized_column(long_col, boundaries=long_boundaries)\n",
    "\n",
    "\n",
    "# bikin crossed column antara lat & long\n",
    "lat_x_long = tf.feature_column.crossed_column([latitude, longitude], hash_bucket_size=100)\n",
    "\n",
    "# jadikan crossed column tadi sebagai indicator column (One-Hot Encoding)\n",
    "crossed_feature = tf.feature_column.indicator_column(lat_x_long)\n",
    "\n",
    "feature_cols.append(crossed_feature)\n",
    "cross_feature_layer = layers.DenseFeatures(feature_cols)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def create_model(_learning_rate, _feature_layer):\n",
    "    _model = tf.keras.Sequential()\n",
    "    _model.add(_feature_layer)\n",
    "    _model.add(layers.Dense(units=1, input_shape=(1,)))\n",
    "    _model.compile(\n",
    "        optimizer=tf.keras.optimizers.RMSprop(learning_rate=_learning_rate),\n",
    "        loss=\"mean_squared_error\",\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "    )\n",
    "    return _model\n",
    "\n",
    "def train_model(_model, _dataset, _epochs, _batch_size, _label_name):\n",
    "    _features = {\n",
    "        name:np.array(value) for name, value in _dataset.items() if name != _label_name\n",
    "    }\n",
    "    _labels = np.array(_dataset[_label_name])\n",
    "    _history = _model.fit(\n",
    "        x=_features,\n",
    "        y=_labels,\n",
    "        batch_size=_batch_size,\n",
    "        epochs=_epochs,\n",
    "        shuffle=True,\n",
    "        verbose=0,\n",
    "    )\n",
    "    _epochs_trained = _history.epoch\n",
    "    _hist = pd.DataFrame(_history.history)\n",
    "    _rmse = _hist[\"root_mean_squared_error\"]\n",
    "\n",
    "    return _epochs_trained, _rmse\n",
    "\n",
    "def plot_loss(_epochs, _rmse):\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Root Mean Squared Error\")\n",
    "    plt.plot(_epochs, _rmse, label=\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.ylim(_rmse.min()*0.95, _rmse.max()*1.05)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'longitude': <tf.Tensor 'ExpandDims_3:0' shape=(100, 1) dtype=float32>, 'latitude': <tf.Tensor 'ExpandDims_2:0' shape=(100, 1) dtype=float32>, 'housing_median_age': <tf.Tensor 'ExpandDims_1:0' shape=(100, 1) dtype=float32>, 'total_rooms': <tf.Tensor 'ExpandDims_7:0' shape=(100, 1) dtype=float32>, 'total_bedrooms': <tf.Tensor 'ExpandDims_6:0' shape=(100, 1) dtype=float32>, 'population': <tf.Tensor 'ExpandDims_5:0' shape=(100, 1) dtype=float32>, 'households': <tf.Tensor 'ExpandDims:0' shape=(100, 1) dtype=float32>, 'median_income': <tf.Tensor 'ExpandDims_4:0' shape=(100, 1) dtype=float32>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\keras\\engine\\training.py:787 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\keras\\engine\\base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\keras\\engine\\sequential.py:383 call\n        outputs = layer(inputs, **kwargs)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\keras\\engine\\base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\keras\\feature_column\\dense_features.py:168 call  **\n        tensor = column.get_dense_tensor(transformation_cache,\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:4303 get_dense_tensor\n        return transformation_cache.get(self, state_manager)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2460 get\n        transformed = column.transform_feature(self, state_manager)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:4239 transform_feature\n        id_weight_pair = self.categorical_column.get_sparse_tensors(\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:4097 get_sparse_tensors\n        transformation_cache.get(self, state_manager), None)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2460 get\n        transformed = column.transform_feature(self, state_manager)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:4045 transform_feature\n        ids_and_weights = key.get_sparse_tensors(transformation_cache,\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2852 get_sparse_tensors\n        input_tensor = transformation_cache.get(self, state_manager)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2460 get\n        transformed = column.transform_feature(self, state_manager)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2774 transform_feature\n        source_tensor = transformation_cache.get(self.source_column, state_manager)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2460 get\n        transformed = column.transform_feature(self, state_manager)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2669 transform_feature\n        input_tensor = transformation_cache.get(self.key, state_manager)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2444 get\n        raise ValueError('Feature {} is not in features dictionary.'.format(key))\n\n    ValueError: Feature longitue is not in features dictionary.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [37]\u001B[0m, in \u001B[0;36m<cell line: 7>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      4\u001B[0m label_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmedian_house_value\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      6\u001B[0m model \u001B[38;5;241m=\u001B[39m create_model(learning_rate, cross_feature_layer)\n\u001B[1;32m----> 7\u001B[0m epochs_trained, rmse \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_df\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m plot_loss(epochs_trained, rmse)\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mEvaluate against test dataset:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Input \u001B[1;32mIn [36]\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(_model, _dataset, _epochs, _batch_size, _label_name)\u001B[0m\n\u001B[0;32m     13\u001B[0m _features \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m     14\u001B[0m     name:np\u001B[38;5;241m.\u001B[39marray(value) \u001B[38;5;28;01mfor\u001B[39;00m name, value \u001B[38;5;129;01min\u001B[39;00m _dataset\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;241m!=\u001B[39m _label_name\n\u001B[0;32m     15\u001B[0m }\n\u001B[0;32m     16\u001B[0m _labels \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(_dataset[_label_name])\n\u001B[1;32m---> 17\u001B[0m _history \u001B[38;5;241m=\u001B[39m \u001B[43m_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_labels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     25\u001B[0m _epochs_trained \u001B[38;5;241m=\u001B[39m _history\u001B[38;5;241m.\u001B[39mepoch\n\u001B[0;32m     26\u001B[0m _hist \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(_history\u001B[38;5;241m.\u001B[39mhistory)\n",
      "File \u001B[1;32m~\\.conda\\envs\\Pleiades\\lib\\site-packages\\keras\\engine\\training.py:1184\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1178\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   1179\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   1180\u001B[0m     step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[0;32m   1181\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m   1182\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m   1183\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1184\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1185\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1186\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    882\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    884\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 885\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    887\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    888\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:933\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    930\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    931\u001B[0m   \u001B[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001B[39;00m\n\u001B[0;32m    932\u001B[0m   initializers \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m--> 933\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_initialize\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madd_initializers_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitializers\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    934\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    935\u001B[0m   \u001B[38;5;66;03m# At this point we know that the initialization is complete (or less\u001B[39;00m\n\u001B[0;32m    936\u001B[0m   \u001B[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001B[39;00m\n\u001B[0;32m    937\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759\u001B[0m, in \u001B[0;36mFunction._initialize\u001B[1;34m(self, args, kwds, add_initializers_to)\u001B[0m\n\u001B[0;32m    756\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lifted_initializer_graph \u001B[38;5;241m=\u001B[39m lifted_initializer_graph\n\u001B[0;32m    757\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_graph_deleter \u001B[38;5;241m=\u001B[39m FunctionDeleter(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lifted_initializer_graph)\n\u001B[0;32m    758\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_concrete_stateful_fn \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m--> 759\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn\u001B[38;5;241m.\u001B[39m_get_concrete_function_internal_garbage_collected(  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m    760\u001B[0m         \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds))\n\u001B[0;32m    762\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minvalid_creator_scope\u001B[39m(\u001B[38;5;241m*\u001B[39munused_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39munused_kwds):\n\u001B[0;32m    763\u001B[0m   \u001B[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066\u001B[0m, in \u001B[0;36mFunction._get_concrete_function_internal_garbage_collected\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   3064\u001B[0m   args, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   3065\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m-> 3066\u001B[0m   graph_function, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maybe_define_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3067\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m graph_function\n",
      "File \u001B[1;32m~\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463\u001B[0m, in \u001B[0;36mFunction._maybe_define_function\u001B[1;34m(self, args, kwargs)\u001B[0m\n\u001B[0;32m   3459\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_define_function_with_shape_relaxation(\n\u001B[0;32m   3460\u001B[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001B[0;32m   3462\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function_cache\u001B[38;5;241m.\u001B[39mmissed\u001B[38;5;241m.\u001B[39madd(call_context_key)\n\u001B[1;32m-> 3463\u001B[0m graph_function \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_graph_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3464\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function_cache\u001B[38;5;241m.\u001B[39mprimary[cache_key] \u001B[38;5;241m=\u001B[39m graph_function\n\u001B[0;32m   3466\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m graph_function, filtered_flat_args\n",
      "File \u001B[1;32m~\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298\u001B[0m, in \u001B[0;36mFunction._create_graph_function\u001B[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001B[0m\n\u001B[0;32m   3293\u001B[0m missing_arg_names \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m   3294\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (arg, i) \u001B[38;5;28;01mfor\u001B[39;00m i, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(missing_arg_names)\n\u001B[0;32m   3295\u001B[0m ]\n\u001B[0;32m   3296\u001B[0m arg_names \u001B[38;5;241m=\u001B[39m base_arg_names \u001B[38;5;241m+\u001B[39m missing_arg_names\n\u001B[0;32m   3297\u001B[0m graph_function \u001B[38;5;241m=\u001B[39m ConcreteFunction(\n\u001B[1;32m-> 3298\u001B[0m     \u001B[43mfunc_graph_module\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc_graph_from_py_func\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3299\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3300\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_python_function\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3301\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3302\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3303\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput_signature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3304\u001B[0m \u001B[43m        \u001B[49m\u001B[43mautograph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_autograph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3305\u001B[0m \u001B[43m        \u001B[49m\u001B[43mautograph_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_autograph_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3306\u001B[0m \u001B[43m        \u001B[49m\u001B[43marg_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43marg_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3307\u001B[0m \u001B[43m        \u001B[49m\u001B[43moverride_flat_arg_shapes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moverride_flat_arg_shapes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3308\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapture_by_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_capture_by_value\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m   3309\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function_attributes,\n\u001B[0;32m   3310\u001B[0m     function_spec\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_spec,\n\u001B[0;32m   3311\u001B[0m     \u001B[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001B[39;00m\n\u001B[0;32m   3312\u001B[0m     \u001B[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001B[39;00m\n\u001B[0;32m   3313\u001B[0m     \u001B[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001B[39;00m\n\u001B[0;32m   3314\u001B[0m     \u001B[38;5;66;03m# ConcreteFunction.\u001B[39;00m\n\u001B[0;32m   3315\u001B[0m     shared_func_graph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m   3316\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m graph_function\n",
      "File \u001B[1;32m~\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007\u001B[0m, in \u001B[0;36mfunc_graph_from_py_func\u001B[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001B[0m\n\u001B[0;32m   1004\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1005\u001B[0m   _, original_func \u001B[38;5;241m=\u001B[39m tf_decorator\u001B[38;5;241m.\u001B[39munwrap(python_func)\n\u001B[1;32m-> 1007\u001B[0m func_outputs \u001B[38;5;241m=\u001B[39m python_func(\u001B[38;5;241m*\u001B[39mfunc_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfunc_kwargs)\n\u001B[0;32m   1009\u001B[0m \u001B[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[39;00m\n\u001B[0;32m   1010\u001B[0m \u001B[38;5;66;03m# TensorArrays and `None`s.\u001B[39;00m\n\u001B[0;32m   1011\u001B[0m func_outputs \u001B[38;5;241m=\u001B[39m nest\u001B[38;5;241m.\u001B[39mmap_structure(convert, func_outputs,\n\u001B[0;32m   1012\u001B[0m                                   expand_composites\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668\u001B[0m, in \u001B[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001B[1;34m(*args, **kwds)\u001B[0m\n\u001B[0;32m    664\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m default_graph\u001B[38;5;241m.\u001B[39m_variable_creator_scope(scope, priority\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m):  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m    665\u001B[0m   \u001B[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001B[39;00m\n\u001B[0;32m    666\u001B[0m   \u001B[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001B[39;00m\n\u001B[0;32m    667\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(compile_with_xla):\n\u001B[1;32m--> 668\u001B[0m     out \u001B[38;5;241m=\u001B[39m weak_wrapped_fn()\u001B[38;5;241m.\u001B[39m__wrapped__(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    669\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32m~\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:994\u001B[0m, in \u001B[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    992\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[0;32m    993\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 994\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mag_error_metadata\u001B[38;5;241m.\u001B[39mto_exception(e)\n\u001B[0;32m    995\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    996\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\keras\\engine\\training.py:787 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\keras\\engine\\base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\keras\\engine\\sequential.py:383 call\n        outputs = layer(inputs, **kwargs)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\keras\\engine\\base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\keras\\feature_column\\dense_features.py:168 call  **\n        tensor = column.get_dense_tensor(transformation_cache,\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:4303 get_dense_tensor\n        return transformation_cache.get(self, state_manager)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2460 get\n        transformed = column.transform_feature(self, state_manager)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:4239 transform_feature\n        id_weight_pair = self.categorical_column.get_sparse_tensors(\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:4097 get_sparse_tensors\n        transformation_cache.get(self, state_manager), None)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2460 get\n        transformed = column.transform_feature(self, state_manager)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:4045 transform_feature\n        ids_and_weights = key.get_sparse_tensors(transformation_cache,\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2852 get_sparse_tensors\n        input_tensor = transformation_cache.get(self, state_manager)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2460 get\n        transformed = column.transform_feature(self, state_manager)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2774 transform_feature\n        source_tensor = transformation_cache.get(self.source_column, state_manager)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2460 get\n        transformed = column.transform_feature(self, state_manager)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2669 transform_feature\n        input_tensor = transformation_cache.get(self.key, state_manager)\n    C:\\Users\\Tenessine\\.conda\\envs\\Pleiades\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2444 get\n        raise ValueError('Feature {} is not in features dictionary.'.format(key))\n\n    ValueError: Feature longitue is not in features dictionary.\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.05\n",
    "epochs = 30\n",
    "batch_size = 100\n",
    "label_name = \"median_house_value\"\n",
    "\n",
    "model = create_model(learning_rate, cross_feature_layer)\n",
    "epochs_trained, rmse = train_model(model, train_df, epochs, batch_size, label_name)\n",
    "plot_loss(epochs_trained, rmse)\n",
    "\n",
    "print(\"\\nEvaluate against test dataset:\")\n",
    "test_features = {\n",
    "    name:np.array(value) for name, value in test_df.items() if name != label_name\n",
    "}\n",
    "test_labels = np.array(test_df[label_name])\n",
    "model.evaluate(test_features, test_labels, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}